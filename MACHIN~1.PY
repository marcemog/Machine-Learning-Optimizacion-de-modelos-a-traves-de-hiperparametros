# -*- coding: utf-8 -*-
"""Machine Learning: Optimización de modelos a través de hiperparámetros.IPY

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fcfth3ylXHzuSyVfm1Ad_JgxOb_JMkV1
"""

import pandas as pd

datos = pd.read_csv("carros.csv")
datos.head()

#situacion con los datos ordenados de la peor manera
datos_ord = datos.sort_values("vendido", ascending=True)
x_ord = datos_ord[["precio", "edad_del_modelo","km_by_year"]]
y_ord = datos_ord["vendido"]
datos_ord.head()

from sklearn.model_selection import cross_validate
from sklearn.dummy import DummyClassifier
import numpy as np

SEED = 301
np.random.seed(SEED)

modelo = DummyClassifier()
results = cross_validate(modelo, x_ord, y_ord, cv = 10, return_train_score=False)
media = results['test_score'].mean()
desviacion_estandar = results['test_score'].std()
print("Accuracy con dummy stratified, 10 = [%.2f, %.2f]" % ((media - 2 * desviacion_estandar)*100, (media + 2 * desviacion_estandar) * 100))

from sklearn.model_selection import cross_validate
from sklearn.tree import DecisionTreeClassifier

SEED = 301
np.random.seed(SEED)

modelo = DecisionTreeClassifier(max_depth=2)
results = cross_validate(modelo, x_ord, y_ord, cv = 10, return_train_score=False)
media = results['test_score'].mean()
desviacion_estandar = results['test_score'].std()
print("Accuracy con cross validation, 10 = [%.2f, %.2f]" % ((media - 2 * desviacion_estandar)*100, (media + 2 * desviacion_estandar) * 100))

#generando datos aleatorios del modelo de carro
np.random.seed(SEED)
datos['modelo'] = datos.edad_del_modelo + np.random.randint(-2, 3, size=10000)
datos.modelo = datos.modelo + abs(datos.modelo.min()) + 1
datos.head()

def imprime_resultados(results):
  media = results['test_score'].mean() * 100
  desviacion = results['test_score'].std() * 100
  print("Accuracy media %.2f" % media)
  print("Intervalo [%.2f, %.2f]" % (media - 2 * desviacion, media + 2 * desviacion))

# GroupKFold en un pipeline con StandardScaler y SVC

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

SEED = 301
np.random.seed(SEED)

scaler = StandardScaler()
modelo = SVC()

pipeline = Pipeline([('transformacion',scaler), ('estimador',modelo)])

cv = GroupKFold(n_splits = 10)
results = cross_validate(pipeline, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=False)
imprime_resultados(results)

# GroupKFold para analizar como el modelo se comporta con nuevos grupos

from sklearn.model_selection import GroupKFold

SEED = 301
np.random.seed(SEED)

cv = GroupKFold(n_splits = 10)
modelo = DecisionTreeClassifier(max_depth=2)
results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=False)
imprime_resultados(results)

from sklearn.tree import export_graphviz
import graphviz

modelo.fit(x_ord, y_ord)
features = x_ord.columns
dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, class_names=['No','Si'], feature_names= features)
graph = graphviz.Source(dot_data)
graph

# GroupKFold para analizar como el modelo se comporta con nuevos grupos
# con max_depth = 3
from sklearn.model_selection import GroupKFold

SEED = 301
np.random.seed(SEED)

cv = GroupKFold(n_splits = 10)
modelo = DecisionTreeClassifier(max_depth=3)
results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=False)
imprime_resultados(results)

from sklearn.tree import export_graphviz
import graphviz

modelo.fit(x_ord, y_ord)
features = x_ord.columns
dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, class_names=['No','Si'], feature_names= features)
graph = graphviz.Source(dot_data)
graph

# GroupKFold para analizar como el modelo se comporta con nuevos grupos
# con max_depth = 10
from sklearn.model_selection import GroupKFold

SEED = 301
np.random.seed(SEED)

cv = GroupKFold(n_splits = 10)
modelo = DecisionTreeClassifier(max_depth=10)
results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=False)
imprime_resultados(results)

"""##Probando parametros

los hiper parametros son los configurados por nosotros antres de entrenar el modelo, los parametros son definidos por el propio modelo
Un hiper parámetro, como bien explicamos, es el parámetro, de los parámetros del árbol o del modelo seleccionado, que nosotros podemos configurar antes del entrenamiento. Son varios de ellos, pero nosotros decidimos trabajar con uno, en este caso max_depth
"""

def iniciar_arbol_decision(max_depth):
    SEED = 301
    np.random.seed(SEED)

    cv = GroupKFold(n_splits = 10)
    modelo = DecisionTreeClassifier(max_depth=max_depth)
    results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=True)
    test_score = results['test_score'].mean()*100
    train_score = results['train_score'].mean()*100
    print('Arbol max_depth = %d, training = %.2f, testing = %.2f' % (max_depth, train_score, test_score))
    tabla = [max_depth, train_score, test_score]
    return tabla

resultados = [iniciar_arbol_decision(i) for i in range(1,33)]
resultados = pd.DataFrame(resultados, columns=['max_depth','train','test'])
resultados.head()

import matplotlib.pyplot as plt
import seaborn as sns
sns.lineplot(x='max_depth', y='train', data=resultados);
sns.lineplot(x='max_depth', y='test', data=resultados);
plt.legend(['Train','Test']);

"""notamos que hay un overfitting de los datos, los resultados de entrenamientos aumentan mientras que los de test disminuyen.. los datso aprenden tanto del entrenamiento que al final solo sirven para eso, no consiguen asimilar nuevas reglas que vienen del escenario real donde vamos a colocar nuestro modelo para ejecutar"""

resultados.sort_values('test', ascending=False).head()

"""Entonces la mejor precisión para nuestros datos de prueba fue el árbol con profundidad 3.
¿cuanto más profundo un árbol, mejor? Depende, va a ser mejor para los datos de entrenamiento, pero si no es mejor para el dato de prueba, para el dato real, entonces estamos viendo un overfitting.
Ahora, el modelo por más profundo que sea, tampoco es bueno para los datos de entrenamiento, también tenemos otra casuística, tenemos un subfitting.

##Aula2: Explorando 2 dimensiones de hiper parámetros
"""

def iniciar_arbol_decision(max_depth, min_samples_leaf):
    SEED = 301
    np.random.seed(SEED)

    cv = GroupKFold(n_splits = 10)
    modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)
    results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=True)
    test_score = results['test_score'].mean()*100
    train_score = results['train_score'].mean()*100
    print('Arbol max_depth = %d, min_samples_leaf = %d, training = %.2f, testing = %.2f' % (max_depth, min_samples_leaf, train_score, test_score))
    tabla = [max_depth, min_samples_leaf, train_score, test_score]
    return tabla

def buscar():
  resultados = []
  for max_depth in range(1,32):
    for min_samples_leaf in [32, 64, 128, 256]:
      tabla = iniciar_arbol_decision(max_depth, min_samples_leaf)
      resultados.append(tabla)
  resultados = pd.DataFrame(resultados, columns = ['max_depth', 'min_samples_leaf', 'train', 'test'])
  return resultados

resultados = buscar()
resultados.head()

resultados.sort_values('test', ascending=False).head()

"""Nosotros tenemos que encontrar la mejor manera de descubrir qué valores seleccionar para nuestra búsqueda de nuestros espacios de parámetros.
Yo he seleccionado cuatro al azar. Pero nosotros tenemos que encontrar la mejor manera de saber cuáles valores podemos colocar en nuestra lista, y para eso existe un método llamado matriz de correlación.
"""

corr = resultados.corr()
corr

"""notamos que a mayor max_depth disminuyen los resultados de test y aumentan los de train
mientras que a mayor min_samples_leaf disminuyen los de train y aumentan los de test
"""

sns.heatmap(corr);

from pandas.plotting import scatter_matrix
scatter_matrix(resultados, figsize=(14,8), alpha=0.3)

"""notamos que a mayor max_depth disminuyen los resultados de test y aumentan los de train mientras que a mayor min_samples_leaf disminuyen los de train y aumentan los de test"""

sns.pairplot(resultados)

#Seaborn Correlation

from string import ascii_letters
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

sns.set_theme(style="white")

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

"""notamos que la correlacion adecuada para mejorar los resultados de test seria un bajo valor de max_depth y un alto valor de min_sample_leaf"""

def buscar():
  resultados = []
  for max_depth in range(1,10):
    for min_samples_leaf in [128, 190, 220, 256]:
      tabla = iniciar_arbol_decision(max_depth, min_samples_leaf)
      resultados.append(tabla)
  resultados = pd.DataFrame(resultados, columns = ['max_depth', 'min_samples_leaf', 'train', 'test'])
  return resultados

resultados = buscar()
resultados.head()

resultados.sort_values('test', ascending=False).head()

"""##Aula3: Trabajando con 3 ó más dimensiones"""

def iniciar_arbol_decision(max_depth, min_samples_leaf, min_samples_split):
    SEED = 301
    np.random.seed(SEED)

    cv = GroupKFold(n_splits = 10)
    modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)
    results = cross_validate(modelo, x_ord, y_ord, cv = cv, groups = datos.modelo, return_train_score=True)
    test_score = results['test_score'].mean()*100
    train_score = results['train_score'].mean()*100
    fit_time = results['fit_time'].mean()
    score_time = results['score_time'].mean()
    print('Arbol max_depth = %d, min_samples_leaf = %d, min_samples_split= %d, training = %.2f, testing = %.2f' % (max_depth, min_samples_leaf, min_samples_split, train_score, test_score))
    tabla = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score, fit_time, score_time]
    return tabla

def buscar():
  resultados = []
  for max_depth in range(1,32):
    for min_samples_leaf in [32, 64, 128, 256]:
      for min_samples_split in [32, 64, 128, 256]:
        tabla = iniciar_arbol_decision(max_depth, min_samples_leaf, min_samples_split)
        resultados.append(tabla)
  resultados = pd.DataFrame(resultados, columns = ['max_depth', 'min_samples_leaf', 'min_samples_split', 'train', 'test', 'fit_time', 'score_time'])
  return resultados

resultados = buscar()
resultados.head()

corr = resultados.corr()

#Seaborn Correlation

from string import ascii_letters
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

sns.set_theme(style="white")

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})

resultados.sort_values('test', ascending=False).head()

"""##Aula4: Explorando espacio de hiperparametros con GridSearchCV"""

from sklearn.model_selection import GridSearchCV

SEED=301
np.random.seed(SEED)

espacio_de_parametros = {
    'max_depth':[3, 5],
    'min_samples_split':[32, 64, 128],
    'min_samples_leaf':[32, 64, 128],
    'criterion':['gini', 'entropy']
}

buscar = GridSearchCV(DecisionTreeClassifier(),
                      espacio_de_parametros,
                      cv = GroupKFold(n_splits = 10))

buscar.fit(x_ord, y_ord, groups = datos.modelo)
resultados = pd.DataFrame(buscar.cv_results_)
resultados.head()

print(buscar.best_params_)
print(buscar.best_score_*100)

mejor = buscar.best_estimator_
mejor

from sklearn.metrics import accuracy_score

prediccion = mejor.predict(x_ord)
accuracy = accuracy_score(prediccion, y_ord) * 100
print('Accuracy para los datos fue %.2f%%' % accuracy)

"""##Aula5: Nested Cross Validation

escenario real
"""

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold

SEED=301
np.random.seed(SEED)

espacio_de_parametros = {
    'max_depth':[3, 5],
    'min_samples_split':[32, 64, 128],
    'min_samples_leaf':[32, 64, 128],
    'criterion':['gini', 'entropy']
}

buscar = GridSearchCV(DecisionTreeClassifier(),
                      espacio_de_parametros,
                      cv = KFold(n_splits = 5, shuffle= True))

buscar.fit(x_ord, y_ord)
resultados = pd.DataFrame(buscar.cv_results_)
resultados.head()

from sklearn.model_selection import cross_val_score

scores = cross_val_score(buscar, x_ord, y_ord, cv=KFold(n_splits=5, shuffle=True))
scores

def imprime_score(scores):
  media= scores.mean()*100
  desviacion = scores.std()*100
  print('Accuracy media %.2f' % media)
  print('Intervalo [%.2f, %.2f]' % (media - 2 * desviacion, media + 2 * desviacion))

imprime_score(scores)  #esto si es la performance o la precisión real sobre los datos reales

mejor = buscar.best_estimator_ 
mejor

#no se por que pero no muestra el criterion=gini, deberia mostrarlo

features = x_ord.columns
dot_data = export_graphviz(mejor, out_file=None, filled=True, rounded=True, class_names=['No','Si'], feature_names= features)
graph = graphviz.Source(dot_data)
graph

